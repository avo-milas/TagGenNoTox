{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7lLpBr4yyFw"
      },
      "source": [
        "### Создание эмбеддингов для аудиодорожек, взятых из видео-файлов с помощью модели YAMNET\n",
        "\n",
        "[ссылка на модель](https://www.kaggle.com/models/google/yamnet)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjPHlVz2d7JD",
        "outputId": "6ff2f25a-0613-45db-9442-1c87a3592be7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import torch\n",
        "import torchaudio\n",
        "from IPython import display\n",
        "from IPython.display import clear_output\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "from scipy.io import wavfile\n",
        "import scipy\n",
        "!apt-get install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLb9RY7CG6tJ"
      },
      "source": [
        "**Дальше идет процесс извлечения и получения эмбеддинга аудио**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "HSqYInDf96JY"
      },
      "outputs": [],
      "source": [
        "def extract_audio_from_video(video_file, output_audio):\n",
        "  # Извлечение аудио из видео с помощью FFmpeg\n",
        "  command = f\"ffmpeg -i {video_file} -q:a 0 -map a -ar 16000 {output_audio} -y\"\n",
        "  subprocess.call(command, shell=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "hITr9Ov9_DYA"
      },
      "outputs": [],
      "source": [
        "def ensure_sample_rate(original_sample_rate, waveform,\n",
        "                       desired_sample_rate=16000):\n",
        "  \"\"\"Resample waveform if required.\"\"\"\n",
        "  if original_sample_rate != desired_sample_rate:\n",
        "    desired_length = int(round(float(len(waveform)) /\n",
        "                               original_sample_rate * desired_sample_rate))\n",
        "    waveform = scipy.signal.resample(waveform, desired_length)\n",
        "  return desired_sample_rate, waveform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "i9gkvjjk_XEh"
      },
      "outputs": [],
      "source": [
        "# Find the name of the class with the top score when mean-aggregated across frames.\n",
        "def class_names_from_csv(class_map_csv_text):\n",
        "  \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n",
        "  class_names = []\n",
        "  with tf.io.gfile.GFile(class_map_csv_text) as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "      class_names.append(row['display_name'])\n",
        "\n",
        "  return class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5g7xMYkebo8"
      },
      "source": [
        "#### Создание эмбеддинга при помощи модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "TS2taKx67y2w"
      },
      "outputs": [],
      "source": [
        "# Загрузка модели YAMNet\n",
        "model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "\n",
        "# Получение карты классов для модели\n",
        "class_map_path = model.class_map_path().numpy()\n",
        "class_names = class_names_from_csv(class_map_path)\n",
        "\n",
        "video_folder = 'extracted_files/videos_2/'\n",
        "video_ids = []\n",
        "audio_logits = np.array([])\n",
        "for video_file in os.listdir(video_folder):\n",
        "  output_audio = 'extracted_files/audios_full/' + video_file[:-3] + 'wav' # создаем новый путь для аудио\n",
        "  full_video_path = 'extracted_files/videos_2/' + video_file\n",
        "  extract_audio_from_video(full_video_path, output_audio)\n",
        "\n",
        "  sample_rate, wav_data = wavfile.read(output_audio, 'rb')\n",
        "\n",
        "  # Преобразование стерео в моно, если необходимо\n",
        "  if wav_data.ndim > 1:\n",
        "    wav_data = np.mean(wav_data, axis=1)\n",
        "  # Приведение к нужной частоте дискретизации\n",
        "  sample_rate, wav_data = ensure_sample_rate(sample_rate, wav_data)\n",
        "\n",
        "  waveform = wav_data / tf.int16.max\n",
        "\n",
        "  # Прогон через модель\n",
        "  scores, embeddings, spectrogram = model(waveform)\n",
        "\n",
        "  # Получение предсказаний\n",
        "  scores_np = scores.numpy()\n",
        "  video_ids.append(video_file)\n",
        "  audio_logits = np.append(scores_np.mean(axis=0), audio_logits, axis = 0) # список эмбеддингов, то что как раз и нужно было на входе из аудиодорожки, shape = 1 x 521, вероятности 521 класса"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGneSSPvgi0T"
      },
      "source": [
        "Создаю csv-file который дальше передается куда нужно..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_to_extract = pd.DataFrame(audio_logits.reshape(-1, 521))\n",
        "data_to_extract['video_ids'] = video_ids"
      ],
      "metadata": {
        "id": "y2fMOWNdwIBR"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('audio_logits_to_extract.csv', 'w') as file:\n",
        "    for index, row in data_to_extract.iterrows():\n",
        "        line = ''\n",
        "        for column in data_to_extract.columns:\n",
        "            line += f'{column}={row[column]}\\t'\n",
        "        print(line.strip(), end='\\n', file=file)"
      ],
      "metadata": {
        "id": "v9C9uonKFk2o"
      },
      "execution_count": 42,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv_tagging",
      "language": "python",
      "name": "venv_tagging"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}